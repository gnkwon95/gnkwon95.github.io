## AWS

현재 Contag (전 ADE) 프로젝트는 AWS EC2 인스턴스에 많이 의존한다.
t2.medium 인스턴스에 프론트, 백이 모두 있고, 각자 다른 포트에서 운영된다.
Gunicorn: ??
DB: 5432
Back Nginx: 80
Front: 3000 (not using Nginx)

이런 구조의 가장 큰 문제는 scalability인데, 서버가 실제로 한번 터지기도 했다.
이를 분산하기 위해 load balancer, Auto Scaling등을 공부하며 여러 개념들을 익혔고, 이를 간략하게나마 정리한다

### 용어 정리

1. EC2 instance
현재 사용하고 있는, 하나의 기본 단위의 서버이다. 스스로의 용량과 CPU를 가지고 있고, Linux 18.04로 무언가 설치하고 운영할 수 있다.
장점: 나한테 익숙하다. Linux Ubuntu에 익숙하기도 하고, 실제 이를 활용한 다양한 툴들 (disown, bg, git 등)을 많이 사용했다.
단점: 확장성이 부족하다. 서버가 커지면 여러 EC2를 연결하고, Auto Scaling을 직접 설정해야한다. 
특정 부분을 때서 일단 각자 다른 서버를 쓰는걸로 시작해서 (DB, Back, Front 3개 서버) 후에는 과부하 걸리는곳 위주로 서버를 두개로 분산하고... 이를 다 트래킹 하고 이해하기에는 벅차다.

2. ECS (Elastic Container Service)
AWS에서 제공하는 컨테이너를 운영하게 해주는 도구이다. 특정 프로그램, 앱을 묶어서 컨테이너에 저장하고, 이 컨테이너를 전체적으로 관리하는 기능이다.
컨테이너의 구성 방식에 따라 완전히 운영 방식이 달라지고, 이를 이해하느라 많은 시간이 걸렸다.
ECS를 만드는 방식은 EC2 cluster와 Fargate가 있다.

3. EC2 Cluster
여러 EC2를 직접 만들고, 각자에 역할을 부여하거나 load balancing (?)을 하는 작업 같다. (실제 사용하지는 않을 예정이라 자세히는 모른다)
디폴트로 EC2 두개를 차지하지만 특정 부하나 시간이 되면 최대 4개까지 할당하고, 사용량이 적을땐 하나만 쓰는 식으로 스케줄링하여 EC2 여러개를 모아 하나의 프로그램을 처리한다.
1번의 단점에서 얘기한것처럼 각 서버들에 대한 이해가 매우 뛰어나야 하고, 얼마나 많은 처리가 필요한지 등을 다 계산할 능력이 있어야 최대 효율로 사용이 가능하다. 
즉, 현재 상황에는 맞지 않다

4. Fargate
Docker와 AWS가 함께 만든 "serverless" ECS방식이다. 이 부분이 매우 이해가 안됐는데, EC2가 하나도 필요하지 않다. 
로컬에서 (혹은 EC2에서) Docker 파일을 만들면 (이 부분은 나중에 설명한다) 이 파일/ 이미지를 Fargate에 업로드 (?) 할 수 있다.
그러면 Fargate가 해당 프로그램에 필요한 서버나 연산, EC2 배분 등을 알아서 배율해서 조절한다. 
즉 EC2 cluster에서 필요한 것을 모두 자동화하고, 모듈화하여 뒤에서 처리를 해준다는 것이다.
다만 (원래 약한) API 사용, 모듈 사용 부분에 대해 보이지 않는 원리들을 받아들이고 써야하기 때문에 조금은 많이 막연할 수 있다.

5. Load Balancer
정의는 네트워크로 들어오는 트래픽을 역으로 proxy를 보내서 다른 서버들로 분산시켜서 한 서버에 들어오는 과부하를 줄이는 것이다.
여러가지 방식이 있는데, 4계층에서 서버 자체에 들어오는 트래픽을 분산하는 기존 방식이 있고, 7계층에서 특정 프로그램에 들어오는 트래픽을 분산하는 방식이 있다.
다행인점은, Fargate를 사용하는 경우 load balancer를 추가하는 기능이 모듈화 되어있다. 즉 설정만 하면 알아서 load balancer를 적용해서 트래픽이 분산된다.
업무 처리의 분산을 대신해주는 load balancer의 사용 자체를 대신(모듈화) 해준다.

6. Auto scaling
1번의 단점, 3번에서 말한 EC2 cluster에서 하는 부분이다. 어떤 상황에는 EC2를 한두개만 쓰고 최대 몇개까지 쓰는것을 설정하면, 알아서 규모를 왔다갔다한다. 
Fargate에서는 애초에 서버를 사용하지 않기에 (serverless) 직접 스케일링이 필요가 없는 것 같다.

### 방향

그래서, 컨택은 Fargate를 쓸 예정이다. 그러기 위해선 우선 Container와 Docker에 대한 이해가 필요하다. 
간단하게, container는 기술이다. Cloud technology가 기술이고, AWS가 기업인것처럼.
프론트 언어가 있고 그중 Python이 있는것처럼 (?) 이해한다.

Docker에 대해서는 다른 파일에서 다루겠다. 

기본적인 구조를 얘기하자면,
Backend -> Nginx로 실행 -> Docker1
Frontend -> Nginx로 실행 -> Docker2
DB -> PostgreSQL -> Docker3
Docker compose 로 이 셋을 새로 compile하고 실행해서 이미지를 합친다.
이 결과물을 Fargate에 올리면 실행이 된다... 돼야한다.



